{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from src.utils import remove_brackets_in_categorical_values\\nfrom src.data_management.cleaning_helpers.renaming_replacing import set_types_file\\nfrom src.data_management.cleaning_helpers.data_checks import general_data_checks '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config import BLD\n",
    "from src.config import SRC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" from src.utils import remove_brackets_in_categorical_values\n",
    "from src.data_management.cleaning_helpers.renaming_replacing import set_types_file\n",
    "from src.data_management.cleaning_helpers.data_checks import general_data_checks \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h=pd.read_stata(\"src/original_data/HHENDDAT_cf_W11.dta\",convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.read_stata(\"src/original_data/PENDDAT_cf_W11.dta\",convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv(\"src/data_management/PENDDAT/penddat_renaming.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnr</th>\n",
       "      <th>hnr</th>\n",
       "      <th>welle</th>\n",
       "      <th>pintjahr</th>\n",
       "      <th>pintmon</th>\n",
       "      <th>zpsex</th>\n",
       "      <th>palter</th>\n",
       "      <th>PD0400</th>\n",
       "      <th>PA0100</th>\n",
       "      <th>PA0300</th>\n",
       "      <th>...</th>\n",
       "      <th>beruf2</th>\n",
       "      <th>casmin</th>\n",
       "      <th>netges</th>\n",
       "      <th>brges</th>\n",
       "      <th>azges1</th>\n",
       "      <th>etakt</th>\n",
       "      <th>alakt</th>\n",
       "      <th>isei1</th>\n",
       "      <th>isei2</th>\n",
       "      <th>migration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000019.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>-9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>59</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>-10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-10</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25469</th>\n",
       "      <td>1.100020e+10</td>\n",
       "      <td>110002041.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25470</th>\n",
       "      <td>1.100020e+10</td>\n",
       "      <td>110002042.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25471</th>\n",
       "      <td>1.100020e+10</td>\n",
       "      <td>110002042.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25472</th>\n",
       "      <td>1.100020e+10</td>\n",
       "      <td>110002045.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25473</th>\n",
       "      <td>1.100021e+10</td>\n",
       "      <td>110002057.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25474 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pnr          hnr  welle  pintjahr  pintmon  zpsex  palter  \\\n",
       "0      1.000002e+09   10000019.0    1.0      2007        5      2      36   \n",
       "1      1.000002e+09   10000019.0    3.0      2009        3      2      38   \n",
       "2      1.000002e+09   10000019.0    1.0      2007        5      1      39   \n",
       "3      1.000002e+09   10000020.0    1.0      2007        4      1      66   \n",
       "4      1.000002e+09   10000020.0    2.0      2008        5      1      67   \n",
       "...             ...          ...    ...       ...      ...    ...     ...   \n",
       "25469  1.100020e+10  110002041.0   11.0      2017        5      1      29   \n",
       "25470  1.100020e+10  110002042.0   11.0      2017        5      1      48   \n",
       "25471  1.100020e+10  110002042.0   11.0      2017        5      1      16   \n",
       "25472  1.100020e+10  110002045.0   11.0      2017        7      1      36   \n",
       "25473  1.100021e+10  110002057.0   11.0      2017        8      1      32   \n",
       "\n",
       "       PD0400  PA0100  PA0300  ...  beruf2  casmin  netges  brges  azges1  \\\n",
       "0           2       8      10  ...       4       4    -3.0     -9    -9.0   \n",
       "1          -9       9       7  ...       4       4    -3.0     -3    -3.0   \n",
       "2           2       8       7  ...       4       7  3000.0     -9    -9.0   \n",
       "3         -10       8       5  ...       4       4    -3.0     -9    -9.0   \n",
       "4           1       8       7  ...       4       4    -3.0     -3   -10.0   \n",
       "...       ...     ...     ...  ...     ...     ...     ...    ...     ...   \n",
       "25469       2      10       4  ...       2       1    -3.0     -3    -3.0   \n",
       "25470       3       1       5  ...       2       1    -3.0     -3    -3.0   \n",
       "25471       3      10       4  ...       2       2    -3.0     -3    -3.0   \n",
       "25472       2       8       7  ...       2       6    -3.0     -3    -3.0   \n",
       "25473       3       7       7  ...       4       7    -3.0     -3    -3.0   \n",
       "\n",
       "       etakt  alakt  isei1  isei2  migration  \n",
       "0         -9     -9     -3   -9.0          1  \n",
       "1          2      2     -3   -9.0          1  \n",
       "2         -9     -9     59   -9.0          1  \n",
       "3         -9     -9    -10   -9.0        -10  \n",
       "4        -10    -10     -3   -9.0          2  \n",
       "...      ...    ...    ...    ...        ...  \n",
       "25469      2      1     -3   -3.0          2  \n",
       "25470      2      1     -3   -3.0          2  \n",
       "25471      2      1     -3   -3.0          2  \n",
       "25472      2      1     -3   -3.0          2  \n",
       "25473      2      2     -3   -3.0          2  \n",
       "\n",
       "[25474 rows x 87 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names=pd.read_csv(\"src/data_management/PENDDAT/penddat_renaming.csv\",sep=\";\")[\"new_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_dict=dict(zip(df.columns,new_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_dict = {k: v for k, v in renaming_dict.items() if pd.notna(v)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.rename(columns=renaming_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnr</th>\n",
       "      <th>hnr</th>\n",
       "      <th>welle</th>\n",
       "      <th>pintjahr</th>\n",
       "      <th>pintmon</th>\n",
       "      <th>zpsex</th>\n",
       "      <th>palter</th>\n",
       "      <th>PD0400</th>\n",
       "      <th>PA0100</th>\n",
       "      <th>PA0300</th>\n",
       "      <th>...</th>\n",
       "      <th>beruf2</th>\n",
       "      <th>casmin</th>\n",
       "      <th>netges</th>\n",
       "      <th>brges</th>\n",
       "      <th>azges1</th>\n",
       "      <th>etakt</th>\n",
       "      <th>alakt</th>\n",
       "      <th>isei1</th>\n",
       "      <th>isei2</th>\n",
       "      <th>migration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000019.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>-9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>59</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>-10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-10</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000002e+09</td>\n",
       "      <td>10000020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25469</th>\n",
       "      <td>1.100020e+10</td>\n",
       "      <td>110002041.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25470</th>\n",
       "      <td>1.100020e+10</td>\n",
       "      <td>110002042.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25471</th>\n",
       "      <td>1.100020e+10</td>\n",
       "      <td>110002042.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25472</th>\n",
       "      <td>1.100020e+10</td>\n",
       "      <td>110002045.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25473</th>\n",
       "      <td>1.100021e+10</td>\n",
       "      <td>110002057.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25474 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pnr          hnr  welle  pintjahr  pintmon  zpsex  palter  \\\n",
       "0      1.000002e+09   10000019.0    1.0      2007        5      2      36   \n",
       "1      1.000002e+09   10000019.0    3.0      2009        3      2      38   \n",
       "2      1.000002e+09   10000019.0    1.0      2007        5      1      39   \n",
       "3      1.000002e+09   10000020.0    1.0      2007        4      1      66   \n",
       "4      1.000002e+09   10000020.0    2.0      2008        5      1      67   \n",
       "...             ...          ...    ...       ...      ...    ...     ...   \n",
       "25469  1.100020e+10  110002041.0   11.0      2017        5      1      29   \n",
       "25470  1.100020e+10  110002042.0   11.0      2017        5      1      48   \n",
       "25471  1.100020e+10  110002042.0   11.0      2017        5      1      16   \n",
       "25472  1.100020e+10  110002045.0   11.0      2017        7      1      36   \n",
       "25473  1.100021e+10  110002057.0   11.0      2017        8      1      32   \n",
       "\n",
       "       PD0400  PA0100  PA0300  ...  beruf2  casmin  netges  brges  azges1  \\\n",
       "0           2       8      10  ...       4       4    -3.0     -9    -9.0   \n",
       "1          -9       9       7  ...       4       4    -3.0     -3    -3.0   \n",
       "2           2       8       7  ...       4       7  3000.0     -9    -9.0   \n",
       "3         -10       8       5  ...       4       4    -3.0     -9    -9.0   \n",
       "4           1       8       7  ...       4       4    -3.0     -3   -10.0   \n",
       "...       ...     ...     ...  ...     ...     ...     ...    ...     ...   \n",
       "25469       2      10       4  ...       2       1    -3.0     -3    -3.0   \n",
       "25470       3       1       5  ...       2       1    -3.0     -3    -3.0   \n",
       "25471       3      10       4  ...       2       2    -3.0     -3    -3.0   \n",
       "25472       2       8       7  ...       2       6    -3.0     -3    -3.0   \n",
       "25473       3       7       7  ...       4       7    -3.0     -3    -3.0   \n",
       "\n",
       "       etakt  alakt  isei1  isei2  migration  \n",
       "0         -9     -9     -3   -9.0          1  \n",
       "1          2      2     -3   -9.0          1  \n",
       "2         -9     -9     59   -9.0          1  \n",
       "3         -9     -9    -10   -9.0        -10  \n",
       "4        -10    -10     -3   -9.0          2  \n",
       "...      ...    ...    ...    ...        ...  \n",
       "25469      2      1     -3   -3.0          2  \n",
       "25470      2      1     -3   -3.0          2  \n",
       "25471      2      1     -3   -3.0          2  \n",
       "25472      2      1     -3   -3.0          2  \n",
       "25473      2      2     -3   -3.0          2  \n",
       "\n",
       "[25474 rows x 87 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _renaming_columns(path):\n",
    "    df=pd.read_stata(path,convert_categoricals=False)\n",
    "    new_names=pd.read_csv(\"src/data_management/PENDDAT/penddat_renaming.csv\",sep=\";\")[\"new_name\"]\n",
    "    renaming_dict=dict(zip(df.columns,new_names))\n",
    "    renaming_dict = {k: v for k, v in renaming_dict.items() if pd.notna(v)}\n",
    "    return df.rename(columns=renaming_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replacing_negative(df,negatives=list(range(-1,-11,-1))):\n",
    "    for i in negatives:\n",
    "        df[df==i]=np.nan\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in glob.glob(\"C:\\Project\\EPP_project\\pass_data_preparation\\src\\original_data\\*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_dataset(path=\"C:\\Project\\EPP_project\\pass_data_preparation\\src\\original_data\"):\n",
    "    a = r\"\\*\"\n",
    "    files = list(glob.glob(path + f\"{a}\"))\n",
    "    #[file for file in glob.glob(path+f\"\\*\")]\n",
    "    name=[]\n",
    "    for i in range(len(files)):\n",
    "        if any(x.isupper() for x in files[i].split(\"\\\\\")[6].split(\"_\")[0]):\n",
    "            name.append(files[i].split(\"\\\\\")[6].split(\"_\")[0])\n",
    "        else:\n",
    "            #a=files[i].split(\"\\\\\")[6].split(\"_\")[0:2]\n",
    "            name.append(files[i].split(\"\\\\\")[6].split(\"_\")[0]+\"_\"+files[i].split(\"\\\\\")[6].split(\"_\")[1])\n",
    "    return name \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HHENDDAT', 'PENDDAT']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_names_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2r3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"2/3\"\n",
    "a.replace(\"/\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'win32'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fix_nans(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_for_two_types_of_missing(df):\n",
    "    # Make sure columns contain only one type of missing\n",
    "    for col in df.columns:\n",
    "        pd_na = any(x is pd.NA for x in list(df[col].unique()))\n",
    "        np_na = any(x is np.nan for x in list(df[col].unique()))\n",
    "        if pd_na & np_na:\n",
    "            print(\n",
    "                f\"{col} contains two types of nans. Will be fixed. Should be checked!\"\n",
    "            )\n",
    "            df[col] = df[col].map(lambda x: _fix_nans(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(panel, replace_dict, rename_df):\n",
    "    \"\"\"Replace and rename values using the replace dictionary.\n",
    "\n",
    "    Args:\n",
    "        panel (pandas.DataFrame): The dataframe which values need to be\n",
    "            replaced or renamed.\n",
    "        replace_dict (dictionary): The replacing dictionary.\n",
    "        rename_df (pandas.DataFrame): The renaming dataframe taken from the\n",
    "            renaming file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The dataframe with the replaced or renamed values.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    out = panel.copy()\n",
    "    # Convert some columns to lower case\n",
    "    if \"mixed_case\" in replace_dict and replace_dict[\"mixed_case\"]:\n",
    "        out[replace_dict[\"mixed_case\"]] = out[replace_dict[\"mixed_case\"]].apply(\n",
    "            lambda x: x.str.lower()\n",
    "        )\n",
    "\n",
    "    # Convert numeric columns\n",
    "    if \"numeric\" in replace_dict and replace_dict[\"numeric\"]:\n",
    "        out[replace_dict[\"numeric\"]] = out[replace_dict[\"numeric\"]].apply(\n",
    "            lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    # Rename variables according to their types.\n",
    "    if \"type renaming\" in replace_dict:\n",
    "\n",
    "        rename_df[\"type\"] = rename_df[\"type\"].replace(\n",
    "            {\n",
    "                \"int\": \"Int64\",\n",
    "                \"float\": \"float64\",\n",
    "                \"bool\": \"boolean\",\n",
    "                \"Categorical\": \"category\",\n",
    "                \"Int\": \"Int64\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for group in replace_dict[\"type renaming\"] and replace_dict[\"type renaming\"]:\n",
    "            filter = rename_df[\"type\"] == group\n",
    "            cols = rename_df.copy()[filter][\"new_name\"].values\n",
    "            for col in cols:\n",
    "                try:\n",
    "                    out[col] = out[col].replace(replace_dict[\"type renaming\"][group])\n",
    "                except Exception:\n",
    "                    print(f\"issue with {col}\")\n",
    "                    continue\n",
    "\n",
    "    # Rename variables in multiple columns.\n",
    "    if \"multicolumn\" in replace_dict and replace_dict[\"multicolumn\"]:\n",
    "        for _j in replace_dict[\"multicolumn\"]:\n",
    "            try:\n",
    "                out.loc[:, replace_dict[\"multicolumn\"][_j][\"columns\"]] = out.loc[\n",
    "                    :, replace_dict[\"multicolumn\"][_j][\"columns\"]\n",
    "                ].replace(replace_dict[\"multicolumn\"][_j][\"dictionary\"])\n",
    "            except Exception:\n",
    "                print(f\"error in {replace_dict['multicolumn'][_j]}\")\n",
    "\n",
    "    # Rename variables according to the renaming dictionary\n",
    "    if \"replacing\" in replace_dict and replace_dict[\"replacing\"]:\n",
    "        for _i in replace_dict[\"replacing\"]:\n",
    "            if _i != \"full_df\":\n",
    "                try:\n",
    "                    out[_i].replace(replace_dict[\"replacing\"][_i], inplace=True)\n",
    "                except TypeError:\n",
    "                    print(f\"type issue with {_i}\")\n",
    "            else:\n",
    "                try:\n",
    "                    out.replace(replace_dict[\"replacing\"][_i], inplace=True)\n",
    "                except TypeError:\n",
    "                    print(f\"type issue with {_i}\")\n",
    "\n",
    "    out = _check_for_two_types_of_missing(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_cleaning(panel, logical_cleaning_dict):\n",
    "    \"\"\"Some logical cleaning specified in logical_cleaning_dict.\n",
    "\n",
    "    Args:\n",
    "        panel (pandas.DataFrame): The dataframe which values need to be\n",
    "            replaced or renamed.\n",
    "        logical_cleaning_dict (dictionary): The specificaiton dictionary.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The dataframe with the replaced or renamed values.\n",
    "\n",
    "    \"\"\"\n",
    "    out = panel.copy()\n",
    "\n",
    "    # Fill nans\n",
    "    if \"fillna\" in logical_cleaning_dict and logical_cleaning_dict[\"fillna\"]:\n",
    "        for col, value in logical_cleaning_dict[\"fillna\"].items():\n",
    "            print(col, out[col].dtype)\n",
    "            out[col] = out[col].fillna(value)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_logically_pl(data, logical_cleaning_dict):\n",
    "    \"\"\"Clean some of the data logically\n",
    "    Args:\n",
    "        data(pandas.DataFrame): The data frame to be cleaned.\n",
    "        logical_cleaning_dict (dictionary): The specification dictionary for automated\n",
    "                                            logical cleaning.\n",
    "    Returns:\n",
    "        pandas.DataFrame: The logically cleaned data frame.\n",
    "    \"\"\"\n",
    "    out = data.copy()\n",
    "    out = logical_cleaning(out, logical_cleaning_dict)\n",
    "    # Divide by 100 because it contains an error;\n",
    "    # now same scale as prv_rente_beitr_2013_m\n",
    "    out[\"prv_rente_beitr_2018_m\"] = out[\"prv_rente_beitr_2018_m\"] / 100\n",
    "    # Calculate average mothly payments into private pension for years 2013 & 2018\n",
    "    out[\"prv_rente_beitr_2013_m\"] = (\n",
    "        out[\"prv_rente_beitr_2013_m\"] * out[\"in_priv_rente_eingezahlt_monate\"] / 12\n",
    "    )\n",
    "    out[\"prv_rente_beitr_2018_m\"] = (\n",
    "        out[\"prv_rente_beitr_2018_m\"] * out[\"in_priv_rente_eingezahlt_monate\"] / 12\n",
    "    )\n",
    "    # Set average mothly payments = 0 when respondent said she\n",
    "    # didnt pay into private pension\n",
    "    out.loc[\n",
    "        out[\"in_priv_rente_eingezahlt\"] == \"Nein\",\n",
    "        [\"prv_rente_beitr_2013_m\", \"prv_rente_beitr_2018_m\"],\n",
    "    ] = 0\n",
    "    #\n",
    "    out[\"prv_rente_beitr_m\"] = out[\"prv_rente_beitr_2013_m\"]\n",
    "    out.loc[out[\"jahr\"] == 2018, \"prv_rente_beitr_m\"] = out.loc[\n",
    "        out[\"jahr\"] == 2018, \"prv_rente_beitr_2018_m\"\n",
    "    ]\n",
    "    # Health variables and Frailty index\n",
    "    med_vars = [\n",
    "        \"med_pl_schw_treppen\",\n",
    "        \"med_pl_schw_taten\",\n",
    "        \"med_pl_schlaf\",\n",
    "        \"med_pl_diabetes\",\n",
    "        \"med_pl_asthma\",\n",
    "        \"med_pl_herzkr\",\n",
    "        \"med_pl_krebs\",\n",
    "        \"med_pl_schlaganf\",\n",
    "        \"med_pl_migraene\",\n",
    "        \"med_pl_bluthdrck\",\n",
    "        \"med_pl_depressiv\",\n",
    "        \"med_pl_demenz\",\n",
    "        \"med_pl_gelenk\",\n",
    "        \"med_pl_ruecken\",\n",
    "        \"med_pl_sonst\",\n",
    "        \"med_pl_raucher\",\n",
    "        \"med_pl_subj_status\",\n",
    "    ]\n",
    "    out[med_vars] = out[med_vars].astype(float)\n",
    "    out[med_vars] = out.groupby(\"p_id\")[\n",
    "        med_vars\n",
    "    ].ffill()  # fill gaps in between surveys with previous values\n",
    "    out[\"bmi_pl\"] = out[\"med_pl_gewicht\"] / ((out[\"med_pl_groesse\"] / 100) ** 2)\n",
    "    out[\"bmi_pl_dummy\"] = (out[\"bmi_pl\"] >= 30).astype(float)\n",
    "    out[\"med_pl_subj_status_dummy\"] = (out[\"med_pl_subj_status\"] >= 3).astype(float)\n",
    "\n",
    "    med_vars.append(\"bmi_pl_dummy\")\n",
    "    med_vars.append(\"med_pl_subj_status_dummy\")\n",
    "    med_vars.remove(\"med_pl_subj_status\")\n",
    "\n",
    "    out[\"frailty_pl\"] = out[med_vars].mean(axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replace_values_pl(data, replace_dict, rename_df):\n",
    "\n",
    "    data = remove_brackets_in_categorical_values(data)\n",
    "\n",
    "    # General replacing\n",
    "    data = replace_values(data, replace_dict, rename_df)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_pl(data):\n",
    "    \"\"\"Check some of the data in the work_schooling database.\n",
    "    Args:\n",
    "        data(pandas.DataFrame): The data frame to be checked.\n",
    "    \"\"\"\n",
    "    out = data.copy()\n",
    "    general_data_checks(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hhenddat(data, rename_df, cleaning_specs):\n",
    "\n",
    "    # Replace values\n",
    "    data = _replace_values_pl(data, cleaning_specs[\"replacing\"], rename_df)\n",
    "\n",
    "    # Set types of variables using renaming file.\n",
    "    data = set_types_file(\n",
    "        panel=data,\n",
    "        rename_df=rename_df,\n",
    "        cat_sep=\"|\",\n",
    "        int_to_float=True,\n",
    "        bool_to_float=True,\n",
    "    )\n",
    "\n",
    "    # Logical cleaning of work schooling\n",
    "    data = _clean_logically_pl(data, cleaning_specs[\"logical_cleaning\"])\n",
    "\n",
    "    # Check some consistency in the data.\n",
    "    _check_pl(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(panel, replace_dict, rename_df):\n",
    "    \"\"\"Replace and rename values using the replace dictionary.\n",
    "\n",
    "    Args:\n",
    "        panel (pandas.DataFrame): The dataframe which values need to be\n",
    "            replaced or renamed.\n",
    "        replace_dict (dictionary): The replacing dictionary.\n",
    "        rename_df (pandas.DataFrame): The renaming dataframe taken from the\n",
    "            renaming file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The dataframe with the replaced or renamed values.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    out = panel.copy()\n",
    "    # Convert some columns to lower case\n",
    "    if \"mixed_case\" in replace_dict and replace_dict[\"mixed_case\"]:\n",
    "        out[replace_dict[\"mixed_case\"]] = out[replace_dict[\"mixed_case\"]].apply(\n",
    "            lambda x: x.str.lower()\n",
    "        )\n",
    "\n",
    "    # Convert numeric columns\n",
    "    if \"numeric\" in replace_dict and replace_dict[\"numeric\"]:\n",
    "        out[replace_dict[\"numeric\"]] = out[replace_dict[\"numeric\"]].apply(\n",
    "            lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    # Rename variables according to their types.\n",
    "    if \"type renaming\" in replace_dict:\n",
    "\n",
    "        rename_df[\"type\"] = rename_df[\"type\"].replace(\n",
    "            {\n",
    "                \"int\": \"Int64\",\n",
    "                \"float\": \"float64\",\n",
    "                \"bool\": \"boolean\",\n",
    "                \"Categorical\": \"category\",\n",
    "                \"Int\": \"Int64\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for group in replace_dict[\"type renaming\"] and replace_dict[\"type renaming\"]:\n",
    "            filter = rename_df[\"type\"] == group\n",
    "            cols = rename_df.copy()[filter][\"new_name\"].values\n",
    "            for col in cols:\n",
    "                try:\n",
    "                    out[col] = out[col].replace(replace_dict[\"type renaming\"][group])\n",
    "                except Exception:\n",
    "                    print(f\"issue with {col}\")\n",
    "                    continue\n",
    "\n",
    "    # Rename variables in multiple columns.\n",
    "    if \"multicolumn\" in replace_dict and replace_dict[\"multicolumn\"]:\n",
    "        for _j in replace_dict[\"multicolumn\"]:\n",
    "            try:\n",
    "                out.loc[:, replace_dict[\"multicolumn\"][_j][\"columns\"]] = out.loc[\n",
    "                    :, replace_dict[\"multicolumn\"][_j][\"columns\"]\n",
    "                ].replace(replace_dict[\"multicolumn\"][_j][\"dictionary\"])\n",
    "            except Exception:\n",
    "                print(f\"error in {replace_dict['multicolumn'][_j]}\")\n",
    "\n",
    "    # Rename variables according to the renaming dictionary\n",
    "    if \"replacing\" in replace_dict and replace_dict[\"replacing\"]:\n",
    "        for _i in replace_dict[\"replacing\"]:\n",
    "            if _i != \"full_df\":\n",
    "                try:\n",
    "                    out[_i].replace(replace_dict[\"replacing\"][_i], inplace=True)\n",
    "                except TypeError:\n",
    "                    print(f\"type issue with {_i}\")\n",
    "            else:\n",
    "                try:\n",
    "                    out.replace(replace_dict[\"replacing\"][_i], inplace=True)\n",
    "                except TypeError:\n",
    "                    print(f\"type issue with {_i}\")\n",
    "\n",
    "    out = _check_for_two_types_of_missing(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src/data_management/HHENDDAT/hhenddat_renaming.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Project\\EPP_project\\pass_data_preparation\\src\\sandbox\\melih_sandbox.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Project/EPP_project/pass_data_preparation/src/sandbox/melih_sandbox.ipynb#ch0000012?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39msrc/data_management/HHENDDAT/hhenddat_renaming.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1212'>1213</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1213'>1214</a>\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1214'>1215</a>\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1215'>1216</a>\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1216'>1217</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1217'>1218</a>\u001b[0m     f,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1218'>1219</a>\u001b[0m     mode,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1219'>1220</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1220'>1221</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1221'>1222</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1222'>1223</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1223'>1224</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1224'>1225</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1225'>1226</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1226'>1227</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=783'>784</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=784'>785</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=785'>786</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=786'>787</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=787'>788</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             handle,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=791'>792</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=792'>793</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=795'>796</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=796'>797</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=797'>798</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src/data_management/HHENDDAT/hhenddat_renaming.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"src/data_management/HHENDDAT/hhenddat_renaming.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f68d72b48bbb1cd886cae2fd8cb3e5126080783d71763ddf61896ec9bf39e27"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pass_data_preparation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
