{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.utils import remove_brackets_in_categorical_values\n",
    "from src.data_management.cleaning_helpers.renaming_replacing import set_types_file\n",
    "from src.data_management.cleaning_helpers.data_checks import general_data_checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_stata(\"src/original_data/HHENDDAT_cf_W11.dta\",convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv(\"src/data_management/PENDDAT/penddat_renaming.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names=pd.read_csv(\"src/data_management/PENDDAT/penddat_renaming.csv\",sep=\";\")[\"new_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_dict=dict(zip(df.columns,new_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(renaming_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hnr': 'p_id',\n",
       " 'welle': 'hh_id',\n",
       " 'hintjahr': 'wave',\n",
       " 'hintmon': 'survey_year',\n",
       " 'HW0300': 'survey_mon',\n",
       " 'HA0100': 'sex',\n",
       " 'HLS0100a': 'age',\n",
       " 'HLS0100b': 'religiosity',\n",
       " 'HLS0200a': nan,\n",
       " 'HLS0200b': nan,\n",
       " 'HLS0300a': nan,\n",
       " 'HLS0300b': nan,\n",
       " 'HLS0400a': nan,\n",
       " 'HLS0400b': nan,\n",
       " 'HLS0500a': nan,\n",
       " 'HLS0500b': nan,\n",
       " 'HLS0600a': nan,\n",
       " 'HLS0600b': nan,\n",
       " 'HLS0700a': nan,\n",
       " 'HLS0700b': nan,\n",
       " 'HLS0800a': nan,\n",
       " 'HLS0800b': nan,\n",
       " 'HLS0900a': nan,\n",
       " 'HLS0900b': nan,\n",
       " 'HLS1000a': nan,\n",
       " 'HLS1000b': nan,\n",
       " 'HLS1100a': nan,\n",
       " 'HLS1100b': nan,\n",
       " 'HLS1200a': nan,\n",
       " 'HLS1200b': nan,\n",
       " 'HLS1300a': nan,\n",
       " 'HLS1300b': nan,\n",
       " 'HLS1400a': nan,\n",
       " 'HLS1400b': nan,\n",
       " 'HLS1500a': nan,\n",
       " 'HLS1500b': nan,\n",
       " 'HLS1600a': nan,\n",
       " 'HLS1600b': 'b5_ext_n_a',\n",
       " 'HLS1700a': 'b5_agree_n_a',\n",
       " 'HLS1700b': 'b5_consc_a',\n",
       " 'HLS1800a': 'b5_neu_a',\n",
       " 'HLS1800b': 'b5_open_a',\n",
       " 'HLS1900a': 'b5_ext_a',\n",
       " 'HLS1900b': 'b5_agree_a',\n",
       " 'HLS2000a': 'b5_consc_n_a',\n",
       " 'HLS2000b': 'b5_neu_n_a',\n",
       " 'HLS2100a': 'b5_open_b',\n",
       " 'HLS2100b': 'b5_ext_n_b',\n",
       " 'HLS2200a': 'b5_agree_n_b',\n",
       " 'HLS2200b': 'b5_consc_b',\n",
       " 'HLS2300a': 'b5_neu_b',\n",
       " 'HLS2300b': 'b5_open_c',\n",
       " 'HLS2400a': 'b5_ext_b',\n",
       " 'HLS2400b': 'b5_agree_b',\n",
       " 'HLS2500a': 'b5_consc_c',\n",
       " 'HLS2500b': 'b5_neu_c',\n",
       " 'HLS2600a': 'b5_open_d',\n",
       " 'HLS2600b': 'b5_open_n_a',\n",
       " 'HLS2700': nan,\n",
       " 'HLS2800a': nan,\n",
       " 'HLS2800b': nan,\n",
       " 'HLS2900a': nan,\n",
       " 'HLS2900b': nan,\n",
       " 'HLS3000a': nan,\n",
       " 'HLS3000b': nan,\n",
       " 'HLS3100a': nan,\n",
       " 'HLS3100b': nan,\n",
       " 'HD0300': nan,\n",
       " 'HEK1500': nan,\n",
       " 'HKI0500': nan,\n",
       " 'hhtyp': nan,\n",
       " 'hhincome': 'nonhh_friends',\n",
       " 'alg2abez': 'nonhh_friends_n',\n",
       " 'oecdincn': nan,\n",
       " 'depindug2': nan,\n",
       " 'depindg2': 'own_child',\n",
       " 'wohnfl': 'educ',\n",
       " 'region': 'job'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns=renaming_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fix_nans(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_for_two_types_of_missing(df):\n",
    "    # Make sure columns contain only one type of missing\n",
    "    for col in df.columns:\n",
    "        pd_na = any(x is pd.NA for x in list(df[col].unique()))\n",
    "        np_na = any(x is np.nan for x in list(df[col].unique()))\n",
    "        if pd_na & np_na:\n",
    "            print(\n",
    "                f\"{col} contains two types of nans. Will be fixed. Should be checked!\"\n",
    "            )\n",
    "            df[col] = df[col].map(lambda x: _fix_nans(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(panel, replace_dict, rename_df):\n",
    "    \"\"\"Replace and rename values using the replace dictionary.\n",
    "\n",
    "    Args:\n",
    "        panel (pandas.DataFrame): The dataframe which values need to be\n",
    "            replaced or renamed.\n",
    "        replace_dict (dictionary): The replacing dictionary.\n",
    "        rename_df (pandas.DataFrame): The renaming dataframe taken from the\n",
    "            renaming file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The dataframe with the replaced or renamed values.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    out = panel.copy()\n",
    "    # Convert some columns to lower case\n",
    "    if \"mixed_case\" in replace_dict and replace_dict[\"mixed_case\"]:\n",
    "        out[replace_dict[\"mixed_case\"]] = out[replace_dict[\"mixed_case\"]].apply(\n",
    "            lambda x: x.str.lower()\n",
    "        )\n",
    "\n",
    "    # Convert numeric columns\n",
    "    if \"numeric\" in replace_dict and replace_dict[\"numeric\"]:\n",
    "        out[replace_dict[\"numeric\"]] = out[replace_dict[\"numeric\"]].apply(\n",
    "            lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    # Rename variables according to their types.\n",
    "    if \"type renaming\" in replace_dict:\n",
    "\n",
    "        rename_df[\"type\"] = rename_df[\"type\"].replace(\n",
    "            {\n",
    "                \"int\": \"Int64\",\n",
    "                \"float\": \"float64\",\n",
    "                \"bool\": \"boolean\",\n",
    "                \"Categorical\": \"category\",\n",
    "                \"Int\": \"Int64\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for group in replace_dict[\"type renaming\"] and replace_dict[\"type renaming\"]:\n",
    "            filter = rename_df[\"type\"] == group\n",
    "            cols = rename_df.copy()[filter][\"new_name\"].values\n",
    "            for col in cols:\n",
    "                try:\n",
    "                    out[col] = out[col].replace(replace_dict[\"type renaming\"][group])\n",
    "                except Exception:\n",
    "                    print(f\"issue with {col}\")\n",
    "                    continue\n",
    "\n",
    "    # Rename variables in multiple columns.\n",
    "    if \"multicolumn\" in replace_dict and replace_dict[\"multicolumn\"]:\n",
    "        for _j in replace_dict[\"multicolumn\"]:\n",
    "            try:\n",
    "                out.loc[:, replace_dict[\"multicolumn\"][_j][\"columns\"]] = out.loc[\n",
    "                    :, replace_dict[\"multicolumn\"][_j][\"columns\"]\n",
    "                ].replace(replace_dict[\"multicolumn\"][_j][\"dictionary\"])\n",
    "            except Exception:\n",
    "                print(f\"error in {replace_dict['multicolumn'][_j]}\")\n",
    "\n",
    "    # Rename variables according to the renaming dictionary\n",
    "    if \"replacing\" in replace_dict and replace_dict[\"replacing\"]:\n",
    "        for _i in replace_dict[\"replacing\"]:\n",
    "            if _i != \"full_df\":\n",
    "                try:\n",
    "                    out[_i].replace(replace_dict[\"replacing\"][_i], inplace=True)\n",
    "                except TypeError:\n",
    "                    print(f\"type issue with {_i}\")\n",
    "            else:\n",
    "                try:\n",
    "                    out.replace(replace_dict[\"replacing\"][_i], inplace=True)\n",
    "                except TypeError:\n",
    "                    print(f\"type issue with {_i}\")\n",
    "\n",
    "    out = _check_for_two_types_of_missing(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_cleaning(panel, logical_cleaning_dict):\n",
    "    \"\"\"Some logical cleaning specified in logical_cleaning_dict.\n",
    "\n",
    "    Args:\n",
    "        panel (pandas.DataFrame): The dataframe which values need to be\n",
    "            replaced or renamed.\n",
    "        logical_cleaning_dict (dictionary): The specificaiton dictionary.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The dataframe with the replaced or renamed values.\n",
    "\n",
    "    \"\"\"\n",
    "    out = panel.copy()\n",
    "\n",
    "    # Fill nans\n",
    "    if \"fillna\" in logical_cleaning_dict and logical_cleaning_dict[\"fillna\"]:\n",
    "        for col, value in logical_cleaning_dict[\"fillna\"].items():\n",
    "            print(col, out[col].dtype)\n",
    "            out[col] = out[col].fillna(value)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_logically_pl(data, logical_cleaning_dict):\n",
    "    \"\"\"Clean some of the data logically\n",
    "    Args:\n",
    "        data(pandas.DataFrame): The data frame to be cleaned.\n",
    "        logical_cleaning_dict (dictionary): The specification dictionary for automated\n",
    "                                            logical cleaning.\n",
    "    Returns:\n",
    "        pandas.DataFrame: The logically cleaned data frame.\n",
    "    \"\"\"\n",
    "    out = data.copy()\n",
    "    out = logical_cleaning(out, logical_cleaning_dict)\n",
    "    # Divide by 100 because it contains an error;\n",
    "    # now same scale as prv_rente_beitr_2013_m\n",
    "    out[\"prv_rente_beitr_2018_m\"] = out[\"prv_rente_beitr_2018_m\"] / 100\n",
    "    # Calculate average mothly payments into private pension for years 2013 & 2018\n",
    "    out[\"prv_rente_beitr_2013_m\"] = (\n",
    "        out[\"prv_rente_beitr_2013_m\"] * out[\"in_priv_rente_eingezahlt_monate\"] / 12\n",
    "    )\n",
    "    out[\"prv_rente_beitr_2018_m\"] = (\n",
    "        out[\"prv_rente_beitr_2018_m\"] * out[\"in_priv_rente_eingezahlt_monate\"] / 12\n",
    "    )\n",
    "    # Set average mothly payments = 0 when respondent said she\n",
    "    # didnt pay into private pension\n",
    "    out.loc[\n",
    "        out[\"in_priv_rente_eingezahlt\"] == \"Nein\",\n",
    "        [\"prv_rente_beitr_2013_m\", \"prv_rente_beitr_2018_m\"],\n",
    "    ] = 0\n",
    "    #\n",
    "    out[\"prv_rente_beitr_m\"] = out[\"prv_rente_beitr_2013_m\"]\n",
    "    out.loc[out[\"jahr\"] == 2018, \"prv_rente_beitr_m\"] = out.loc[\n",
    "        out[\"jahr\"] == 2018, \"prv_rente_beitr_2018_m\"\n",
    "    ]\n",
    "    # Health variables and Frailty index\n",
    "    med_vars = [\n",
    "        \"med_pl_schw_treppen\",\n",
    "        \"med_pl_schw_taten\",\n",
    "        \"med_pl_schlaf\",\n",
    "        \"med_pl_diabetes\",\n",
    "        \"med_pl_asthma\",\n",
    "        \"med_pl_herzkr\",\n",
    "        \"med_pl_krebs\",\n",
    "        \"med_pl_schlaganf\",\n",
    "        \"med_pl_migraene\",\n",
    "        \"med_pl_bluthdrck\",\n",
    "        \"med_pl_depressiv\",\n",
    "        \"med_pl_demenz\",\n",
    "        \"med_pl_gelenk\",\n",
    "        \"med_pl_ruecken\",\n",
    "        \"med_pl_sonst\",\n",
    "        \"med_pl_raucher\",\n",
    "        \"med_pl_subj_status\",\n",
    "    ]\n",
    "    out[med_vars] = out[med_vars].astype(float)\n",
    "    out[med_vars] = out.groupby(\"p_id\")[\n",
    "        med_vars\n",
    "    ].ffill()  # fill gaps in between surveys with previous values\n",
    "    out[\"bmi_pl\"] = out[\"med_pl_gewicht\"] / ((out[\"med_pl_groesse\"] / 100) ** 2)\n",
    "    out[\"bmi_pl_dummy\"] = (out[\"bmi_pl\"] >= 30).astype(float)\n",
    "    out[\"med_pl_subj_status_dummy\"] = (out[\"med_pl_subj_status\"] >= 3).astype(float)\n",
    "\n",
    "    med_vars.append(\"bmi_pl_dummy\")\n",
    "    med_vars.append(\"med_pl_subj_status_dummy\")\n",
    "    med_vars.remove(\"med_pl_subj_status\")\n",
    "\n",
    "    out[\"frailty_pl\"] = out[med_vars].mean(axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replace_values_pl(data, replace_dict, rename_df):\n",
    "\n",
    "    data = remove_brackets_in_categorical_values(data)\n",
    "\n",
    "    # General replacing\n",
    "    data = replace_values(data, replace_dict, rename_df)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_pl(data):\n",
    "    \"\"\"Check some of the data in the work_schooling database.\n",
    "    Args:\n",
    "        data(pandas.DataFrame): The data frame to be checked.\n",
    "    \"\"\"\n",
    "    out = data.copy()\n",
    "    general_data_checks(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hhenddat(data, rename_df, cleaning_specs):\n",
    "\n",
    "    # Replace values\n",
    "    data = _replace_values_pl(data, cleaning_specs[\"replacing\"], rename_df)\n",
    "\n",
    "    # Set types of variables using renaming file.\n",
    "    data = set_types_file(\n",
    "        panel=data,\n",
    "        rename_df=rename_df,\n",
    "        cat_sep=\"|\",\n",
    "        int_to_float=True,\n",
    "        bool_to_float=True,\n",
    "    )\n",
    "\n",
    "    # Logical cleaning of work schooling\n",
    "    data = _clean_logically_pl(data, cleaning_specs[\"logical_cleaning\"])\n",
    "\n",
    "    # Check some consistency in the data.\n",
    "    _check_pl(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(panel, replace_dict, rename_df):\n",
    "    \"\"\"Replace and rename values using the replace dictionary.\n",
    "\n",
    "    Args:\n",
    "        panel (pandas.DataFrame): The dataframe which values need to be\n",
    "            replaced or renamed.\n",
    "        replace_dict (dictionary): The replacing dictionary.\n",
    "        rename_df (pandas.DataFrame): The renaming dataframe taken from the\n",
    "            renaming file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The dataframe with the replaced or renamed values.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    out = panel.copy()\n",
    "    # Convert some columns to lower case\n",
    "    if \"mixed_case\" in replace_dict and replace_dict[\"mixed_case\"]:\n",
    "        out[replace_dict[\"mixed_case\"]] = out[replace_dict[\"mixed_case\"]].apply(\n",
    "            lambda x: x.str.lower()\n",
    "        )\n",
    "\n",
    "    # Convert numeric columns\n",
    "    if \"numeric\" in replace_dict and replace_dict[\"numeric\"]:\n",
    "        out[replace_dict[\"numeric\"]] = out[replace_dict[\"numeric\"]].apply(\n",
    "            lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    # Rename variables according to their types.\n",
    "    if \"type renaming\" in replace_dict:\n",
    "\n",
    "        rename_df[\"type\"] = rename_df[\"type\"].replace(\n",
    "            {\n",
    "                \"int\": \"Int64\",\n",
    "                \"float\": \"float64\",\n",
    "                \"bool\": \"boolean\",\n",
    "                \"Categorical\": \"category\",\n",
    "                \"Int\": \"Int64\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for group in replace_dict[\"type renaming\"] and replace_dict[\"type renaming\"]:\n",
    "            filter = rename_df[\"type\"] == group\n",
    "            cols = rename_df.copy()[filter][\"new_name\"].values\n",
    "            for col in cols:\n",
    "                try:\n",
    "                    out[col] = out[col].replace(replace_dict[\"type renaming\"][group])\n",
    "                except Exception:\n",
    "                    print(f\"issue with {col}\")\n",
    "                    continue\n",
    "\n",
    "    # Rename variables in multiple columns.\n",
    "    if \"multicolumn\" in replace_dict and replace_dict[\"multicolumn\"]:\n",
    "        for _j in replace_dict[\"multicolumn\"]:\n",
    "            try:\n",
    "                out.loc[:, replace_dict[\"multicolumn\"][_j][\"columns\"]] = out.loc[\n",
    "                    :, replace_dict[\"multicolumn\"][_j][\"columns\"]\n",
    "                ].replace(replace_dict[\"multicolumn\"][_j][\"dictionary\"])\n",
    "            except Exception:\n",
    "                print(f\"error in {replace_dict['multicolumn'][_j]}\")\n",
    "\n",
    "    # Rename variables according to the renaming dictionary\n",
    "    if \"replacing\" in replace_dict and replace_dict[\"replacing\"]:\n",
    "        for _i in replace_dict[\"replacing\"]:\n",
    "            if _i != \"full_df\":\n",
    "                try:\n",
    "                    out[_i].replace(replace_dict[\"replacing\"][_i], inplace=True)\n",
    "                except TypeError:\n",
    "                    print(f\"type issue with {_i}\")\n",
    "            else:\n",
    "                try:\n",
    "                    out.replace(replace_dict[\"replacing\"][_i], inplace=True)\n",
    "                except TypeError:\n",
    "                    print(f\"type issue with {_i}\")\n",
    "\n",
    "    out = _check_for_two_types_of_missing(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src/data_management/HHENDDAT/hhenddat_renaming.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Project\\EPP_project\\pass_data_preparation\\src\\sandbox\\melih_sandbox.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Project/EPP_project/pass_data_preparation/src/sandbox/melih_sandbox.ipynb#ch0000012?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39msrc/data_management/HHENDDAT/hhenddat_renaming.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1212'>1213</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1213'>1214</a>\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1214'>1215</a>\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1215'>1216</a>\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1216'>1217</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1217'>1218</a>\u001b[0m     f,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1218'>1219</a>\u001b[0m     mode,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1219'>1220</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1220'>1221</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1221'>1222</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1222'>1223</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1223'>1224</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1224'>1225</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1225'>1226</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1226'>1227</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pass_data_preparation\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=783'>784</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=784'>785</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=785'>786</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=786'>787</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=787'>788</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             handle,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=791'>792</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=792'>793</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=795'>796</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=796'>797</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/pass_data_preparation/lib/site-packages/pandas/io/common.py?line=797'>798</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src/data_management/HHENDDAT/hhenddat_renaming.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"src/data_management/HHENDDAT/hhenddat_renaming.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f68d72b48bbb1cd886cae2fd8cb3e5126080783d71763ddf61896ec9bf39e27"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pass_data_preparation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
